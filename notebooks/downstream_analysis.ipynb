{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Downstream Analysis Pipeline\n",
    "\n",
    "This notebook demonstrates the complete downstream analysis workflow for segmented multiplex tissue imaging data:\n",
    "\n",
    "1. **Feature Extraction** - Extract morphology and marker intensities from segmented cells\n",
    "2. **Preprocessing** - Scale, filter, and clean the feature data\n",
    "3. **Clustering** - PCA, Harmony batch correction, and Louvain clustering\n",
    "4. **Visualization** - Heatmaps, UMAP plots, and composition analysis\n",
    "5. **QuPath Export** - Export cell annotations as GeoJSON for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path if running from notebooks directory\n",
    "src_path = Path(\"../src\").resolve()\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Analysis imports\n",
    "from analysis import (\n",
    "    # Feature extraction\n",
    "    extract_features,\n",
    "    extract_features_batch,\n",
    "    # Preprocessing\n",
    "    identify_marker_columns,\n",
    "    scale_features,\n",
    "    filter_markers,\n",
    "    filter_cells,\n",
    "    remove_outliers,\n",
    "    # Clustering\n",
    "    ClusteringConfig,\n",
    "    to_anndata,\n",
    "    run_clustering,\n",
    "    clustering_pipeline,\n",
    "    add_clusters_to_dataframe,\n",
    "    # Visualization\n",
    "    plot_marker_heatmap,\n",
    "    plot_cluster_composition,\n",
    "    plot_marker_distributions,\n",
    "    plot_umap,\n",
    "    plot_pca_variance,\n",
    "    # Export\n",
    "    export_to_geojson,\n",
    "    export_mcmicro_batch,\n",
    ")\n",
    "\n",
    "# Pseudochannel imports (for finding experiments)\n",
    "from pseudochannel import find_mcmicro_experiments\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure paths\n",
    "# NOTE: Update these paths to match your data location\n",
    "\n",
    "ROOT_PATH = Path(\"../data\")  # Root directory containing MCMICRO experiments\n",
    "\n",
    "# Or for a single experiment:\n",
    "# MASK_PATH = Path(\"../data/experiment/segmentation/seg_mask.tif\")\n",
    "# IMAGE_PATH = Path(\"../data/experiment/background/image.ome.tiff\")\n",
    "# MARKER_PATH = Path(\"../data/experiment/markers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-header",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction\n",
    "\n",
    "Extract morphology and marker intensity features from segmented cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-single-header",
   "metadata": {},
   "source": [
    "### 2.1 Single Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract features from a single experiment\n",
    "# # Uncomment and update paths to use:\n",
    "\n",
    "# features_df = extract_features(\n",
    "#     mask_path=MASK_PATH,\n",
    "#     image_path=IMAGE_PATH,\n",
    "#     marker_file=MARKER_PATH,\n",
    "#     mcmicro_markers=True,\n",
    "#     exclude_markers=[\"DAPI\", \"Background\"],  # Markers to exclude\n",
    "#     roi_name=\"experiment_1\",  # Optional ROI identifier\n",
    "# )\n",
    "# features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-batch-header",
   "metadata": {},
   "source": [
    "### 2.2 Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Batch extract features from all experiments\n",
    "# # This finds experiments with segmentation masks and extracts features from each\n",
    "\n",
    "# features_df = extract_features_batch(\n",
    "#     root_path=ROOT_PATH,\n",
    "#     segmentation_folder=\"segmentation\",\n",
    "#     mask_filename=\"seg_mask.tif\",\n",
    "#     output_folder=\"analysis\",\n",
    "#     output_filename=\"features.csv\",\n",
    "#     mcmicro_markers=True,\n",
    "#     exclude_markers=[\"DAPI\", \"Background\"],\n",
    "#     save_individual=True,  # Save per-experiment CSVs\n",
    "#     progress=True,\n",
    "# )\n",
    "# print(f\"Extracted features for {len(features_df)} cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or load pre-extracted features:\n",
    "# features_df = pd.read_csv(ROOT_PATH / \"combined_features.csv\")\n",
    "\n",
    "# For demonstration, create synthetic data\n",
    "np.random.seed(42)\n",
    "n_cells = 5000\n",
    "n_markers = 20\n",
    "\n",
    "features_df = pd.DataFrame({\n",
    "    \"ROI\": np.random.choice([\"sample_1\", \"sample_2\", \"sample_3\"], n_cells),\n",
    "    \"label\": np.arange(1, n_cells + 1),\n",
    "    \"centroid_x\": np.random.uniform(0, 2000, n_cells),\n",
    "    \"centroid_y\": np.random.uniform(0, 2000, n_cells),\n",
    "    \"area\": np.random.lognormal(6, 0.5, n_cells),\n",
    "})\n",
    "\n",
    "# Add synthetic marker intensities\n",
    "marker_names = [f\"Marker_{i}\" for i in range(1, n_markers + 1)]\n",
    "for marker in marker_names:\n",
    "    features_df[marker] = np.random.lognormal(0, 1, n_cells)\n",
    "\n",
    "print(f\"Features shape: {features_df.shape}\")\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocess-header",
   "metadata": {},
   "source": [
    "## 3. Preprocessing\n",
    "\n",
    "Clean, filter, and normalize the feature data before clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identify-markers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify marker columns automatically\n",
    "marker_cols = identify_marker_columns(features_df)\n",
    "print(f\"Detected {len(marker_cols)} marker columns:\")\n",
    "print(marker_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filter-cells",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter cells by morphology (e.g., remove debris and large aggregates)\n",
    "print(f\"Before filtering: {len(features_df)} cells\")\n",
    "\n",
    "filtered_df = filter_cells(\n",
    "    features_df,\n",
    "    min_area=100,    # Minimum cell area\n",
    "    max_area=5000,   # Maximum cell area\n",
    ")\n",
    "print(f\"After area filtering: {len(filtered_df)} cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remove-outliers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outlier cells (optional)\n",
    "filtered_df = remove_outliers(\n",
    "    filtered_df,\n",
    "    columns=marker_cols,\n",
    "    method=\"percentile\",\n",
    "    lower=0.01,\n",
    "    upper=0.99,\n",
    ")\n",
    "print(f\"After outlier removal: {len(filtered_df)} cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scale-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale marker intensities\n",
    "# Options: 'standard' (z-score), 'minmax' (0-1), 'log' (log1p)\n",
    "\n",
    "scaled_df = scale_features(\n",
    "    filtered_df,\n",
    "    method=\"standard\",\n",
    "    columns=marker_cols,\n",
    ")\n",
    "\n",
    "print(\"Scaled marker statistics:\")\n",
    "scaled_df[marker_cols].describe().loc[[\"mean\", \"std\"]].round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cluster-header",
   "metadata": {},
   "source": [
    "## 4. Clustering\n",
    "\n",
    "Perform dimensionality reduction and clustering to identify cell populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cluster-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure clustering parameters\n",
    "config = ClusteringConfig(\n",
    "    n_pcs=30,                      # Number of principal components\n",
    "    harmony_vars=[\"ROI\"],          # Batch correction variables\n",
    "    n_neighbors=15,                # Neighbors for graph construction\n",
    "    louvain_resolution=1.0,        # Cluster resolution (higher = more clusters)\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(f\"Clustering config: {config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-clustering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the full clustering pipeline\n",
    "# This performs: PCA -> Harmony batch correction -> Louvain clustering -> UMAP\n",
    "\n",
    "adata = clustering_pipeline(\n",
    "    scaled_df,\n",
    "    config=config,\n",
    "    marker_columns=marker_cols,\n",
    ")\n",
    "\n",
    "print(f\"AnnData shape: {adata.shape}\")\n",
    "print(f\"Number of clusters: {adata.obs['louvain'].nunique()}\")\n",
    "print(f\"Cluster sizes:\\n{adata.obs['louvain'].value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add-clusters-df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster assignments back to the DataFrame\n",
    "result_df = add_clusters_to_dataframe(\n",
    "    scaled_df,\n",
    "    adata,\n",
    "    cluster_key=\"louvain\",\n",
    "    column_name=\"cluster\",\n",
    ")\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-header",
   "metadata": {},
   "source": [
    "## 5. Visualization\n",
    "\n",
    "Visualize clustering results and marker expression patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-pca-header",
   "metadata": {},
   "source": [
    "### 5.1 PCA Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-pca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PCA variance explained\n",
    "plot_pca_variance(adata, n_pcs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-umap-header",
   "metadata": {},
   "source": [
    "### 5.2 UMAP Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-umap",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP colored by cluster\n",
    "plot_umap(adata, color=\"louvain\", title=\"UMAP - Louvain Clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-umap-roi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP colored by ROI (to check batch correction)\n",
    "plot_umap(adata, color=\"ROI\", title=\"UMAP - By ROI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-heatmap-header",
   "metadata": {},
   "source": [
    "### 5.3 Marker Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-heatmap",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marker expression heatmap by cluster\n",
    "plot_marker_heatmap(\n",
    "    adata,\n",
    "    groupby=\"louvain\",\n",
    "    standard_scale=\"var\",  # Normalize per marker\n",
    "    cmap=\"viridis\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-composition-header",
   "metadata": {},
   "source": [
    "### 5.4 Cluster Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster composition by ROI\n",
    "plot_cluster_composition(\n",
    "    result_df,\n",
    "    cluster_col=\"cluster\",\n",
    "    group_col=\"ROI\",\n",
    "    normalize=True,\n",
    "    title=\"Cluster Composition by Sample\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-distributions-header",
   "metadata": {},
   "source": [
    "### 5.5 Marker Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-distributions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marker distributions by cluster (first 8 markers)\n",
    "plot_marker_distributions(\n",
    "    result_df,\n",
    "    markers=marker_cols[:8],\n",
    "    hue=\"cluster\",\n",
    "    kind=\"box\",\n",
    "    ncols=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export-header",
   "metadata": {},
   "source": [
    "## 6. QuPath Export\n",
    "\n",
    "Export cell annotations to GeoJSON format for visualization in QuPath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export single experiment to GeoJSON\n",
    "# # Uncomment and update paths to use:\n",
    "\n",
    "# # Build cluster assignments dict for a specific ROI\n",
    "# roi_df = result_df[result_df[\"ROI\"] == \"sample_1\"]\n",
    "# cluster_assignments = dict(zip(roi_df[\"label\"].astype(int), roi_df[\"cluster\"]))\n",
    "\n",
    "# export_to_geojson(\n",
    "#     mask_path=MASK_PATH,\n",
    "#     output_path=Path(\"../output/annotations.geojson\"),\n",
    "#     cluster_assignments=cluster_assignments,\n",
    "#     simplify_tolerance=1.0,  # Polygon simplification\n",
    "#     alpha=128,  # Fill transparency\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Batch export all experiments\n",
    "# # Uncomment and update to use:\n",
    "\n",
    "# exported = export_mcmicro_batch(\n",
    "#     root_path=ROOT_PATH,\n",
    "#     features_df=result_df,\n",
    "#     cluster_col=\"cluster\",\n",
    "#     label_col=\"label\",\n",
    "#     roi_col=\"ROI\",\n",
    "#     output_folder=\"qupath\",\n",
    "#     output_filename=\"annotations.geojson\",\n",
    "#     progress=True,\n",
    "# )\n",
    "# print(f\"Exported {len(exported)} GeoJSON files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-header",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-csv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save clustered features to CSV\n",
    "# result_df.to_csv(ROOT_PATH / \"clustered_features.csv\", index=False)\n",
    "# print(\"Saved clustered features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-anndata",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save AnnData object (includes all embeddings and metadata)\n",
    "# adata.write(ROOT_PATH / \"analysis.h5ad\")\n",
    "# print(\"Saved AnnData object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save clustering config for reproducibility\n",
    "import yaml\n",
    "\n",
    "analysis_config = {\n",
    "    \"preprocessing\": {\n",
    "        \"min_area\": 100,\n",
    "        \"max_area\": 5000,\n",
    "        \"outlier_method\": \"percentile\",\n",
    "        \"outlier_lower\": 0.01,\n",
    "        \"outlier_upper\": 0.99,\n",
    "        \"scaling_method\": \"standard\",\n",
    "    },\n",
    "    \"clustering\": {\n",
    "        \"n_pcs\": config.n_pcs,\n",
    "        \"harmony_vars\": config.harmony_vars,\n",
    "        \"n_neighbors\": config.n_neighbors,\n",
    "        \"louvain_resolution\": config.louvain_resolution,\n",
    "        \"random_state\": config.random_state,\n",
    "    },\n",
    "}\n",
    "\n",
    "# # Save config\n",
    "# with open(ROOT_PATH / \"analysis_config.yaml\", \"w\") as f:\n",
    "#     yaml.dump(analysis_config, f, default_flow_style=False)\n",
    "# print(\"Saved analysis config\")\n",
    "\n",
    "# Display config\n",
    "print(yaml.dump(analysis_config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the complete downstream analysis pipeline:\n",
    "\n",
    "1. **Feature Extraction** - Extracted morphology and marker intensities from segmented cells\n",
    "2. **Preprocessing** - Filtered cells by size, removed outliers, and scaled features\n",
    "3. **Clustering** - Performed PCA, Harmony batch correction, and Louvain clustering\n",
    "4. **Visualization** - Created UMAP plots, heatmaps, and composition charts\n",
    "5. **Export** - Prepared GeoJSON files for QuPath visualization\n",
    "\n",
    "### Output Files\n",
    "\n",
    "After running on real data, the following outputs are created:\n",
    "\n",
    "```\n",
    "root/\n",
    "├── experiment/\n",
    "│   ├── analysis/\n",
    "│   │   └── features.csv        # Per-cell features\n",
    "│   └── qupath/\n",
    "│       └── annotations.geojson # QuPath annotations\n",
    "├── clustered_features.csv      # Combined features with clusters\n",
    "├── analysis.h5ad               # AnnData with embeddings\n",
    "└── analysis_config.yaml        # Analysis parameters\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pseudochannel_gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
